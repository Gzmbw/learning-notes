%-*- coding: UTF-8 -*-
% notes.tex
%
\documentclass[UTF8]{article}
\usepackage{geometry}
\geometry{a4paper, centering, scale=0.8}
\usepackage{minted}
\usepackage{hyperref}
\usepackage{indentfirst}    % to indent the first paragraph of a section
\usepackage{graphicx}       % to insert figures
\usepackage{amsmath}        % to type some math equations
\usepackage{amssymb}        % to use some special math font
\usepackage{IEEEtrantools}  % to use IEEEeqnarray
\usepackage{ulem}           % to use stikeout command \sout{} (don't work in math mode)
\usepackage{algorithm2e}    % to use algorithm environment
\usepackage{multicol}       % to display some content in multi-columns
\setlength{\columnseprule}{0.4pt}   % set the rule's width of multicols
\setlength{\columnsep}{5em}         % set the sep of multicols

% Math notation
% refered to https://github.com/exacity/deeplearningbook-chinese/blob/master/math_symbol.tex
\newcommand{\Scalar}[1]{\mathit{#1}}                % Scalar, the default math font
\newcommand{\Vector}[1]{\boldsymbol{\mathit{#1}}}   % Vector
\newcommand{\Matrix}[1]{\boldsymbol{\mathit{#1}}}   % Matrix
\newcommand{\Tensor}[1]{\textsf{\textbf{#1}}}       % Tensor
\newcommand{\Set}[1]{\mathbb{#1}}                   % Set
\newcommand{\Cal}[1]{\mathcal{#1}}                  % Math Cal

% Draw the lines in a matrix, which is composed by a series of vectors
\newcommand{\vRule}{\rule{0.3pt}{10mm}}             % vertical rule
\newcommand{\hRule}{\,\rule[1mm]{10mm}{0.3pt}\,}    % horizontal rule

\title{Deep Learning Specialization \\
        Neural Networks and Deep Learning \\
        Learning Notes}
\author{Du Ang \\ \texttt{du2ang233@gmail.com} }
\date{\today}

\begin{document}
\maketitle

\tableofcontents
\newpage

\section{Welcome}
\begin{quote}
    \emph{AI is the new Electricity. --- Andrew Ng}
\end{quote}

Electricity had once transformed countless industries: transportation, manufacturing, healthcare,
communications, and more.

AI will now bring about an equally big transformation.

\paragraph{Courses in this sequence (Specialization):}
\begin{enumerate}
    \item \emph{Neural Networks and Deep Learning}
    \item \emph{Improving Deep Neural Networks: Hyperparameter tuning, Regularization and
    Optimization}
    \item \emph{Structuring Machine Learning Projects}
    \item \emph{Convolutional Neural Networks}
    \item \emph{Sequence Models}
\end{enumerate}

\section{Introduction to Deep Learning}
\subsection{What is a neural network?}
It is powerful learning algorithm inspired by how the brain works.
\subsubsection{Single neural network}
Given data about the size of houses on the real estate market and you want to fit a function that
will predict their price. It is a linear regression problem because the price as a function of size
is a continuous output.

We know the prices can never be negative so we are creating a function called Rectified Linear Unit
(ReLU) which starts at zero.
\begin{figure}[htb]
    \centering
    \includegraphics[width=40em]{figures/single-nn}
    \caption{The ``Housing Price Prediction'' problem. The input is the size of the house
    ($x$); The output is the price ($y$); The ``neuron'' implements the function
    ReLU.}
\end{figure}

\subsubsection{Multiple neural network}
The price of a house can be affected by other features such as size, number of bedrooms, zip code
and wealth. The role of the neural network is to predicted the price and it will automatically
generate the hidden units. We only need to give the inputs x and the output y.
\begin{figure}[htb]
    \centering
    \includegraphics[width=30em]{figures/multiple-nn}
    \caption{Multiple neural network}
\end{figure}

\subsection{Supervised Learning}
In supervised learning, we are given a data set and already know about what our correct output
should look like, having the idea that there is a relationship between the input and the output.

Supervised learning problems are categorized into ``regression'' and ``classification'' problems.
In a regression problem, we are trying to predict results with a continuous output, meaning that we
are trying to map input variables to some continuous function. In a classification problem, we are
instead trying to predict results in a discrete output. In other words, we are trying to map input
variables into discrete categories.

Here are some example of supervised learning:
\begin{table}[htb]
\centering
\caption{Supervised Learning Applications}
\begin{tabular}{lllc}
\textbf{Input($x$)} & \textbf{Output($y$)} & \textbf{Application}
& \textbf{NN Types} \\ \hline
Home features & Price & Real Estate & Standard NN \\
Ad, user info & Click on ad? (0/1) & Online Advertising & Standard NN \\
Image & Object (1, ..., 1000) & Photo tagging & CNN \\
Audio & Text transcript & Speech Recognition & RNN \\
English & Chinese & Machine translation & RNN \\
Image, Radar info & Position of other cars & Autonomous driving & Custom/Hybrid \\
\end{tabular}
\end{table}

There are different types of neural network, for example, Convolutional Neural Network (CNN) used
often for image application and Recurrent Neural Network (RNN) used for one-dimensional sequence
data such as translating English to Chinese or a temporal component such as text transcript. As for
the autonomous driving, it is a hybrid neural network architecture.

\subsubsection{Structured vs unstructed data}
Structed data refers to things that has a defined meaning such as price, age whereas unstructed
data refers to thing like pixel, raw audio, text.

\subsection{Why is Deep Learning taking off?}
Deep learning is taking off due to a large amount of data available through the digitization of the
society, faster computation and innovation in the development of neural network algorithm.
\begin{figure}[htb]
    \centering
    \includegraphics[width=40em]{figures/deep-nn-scale}
    \caption{Scale drives deep learning progress}
\end{figure}

Two things have to be considered to get to the high level of performance:
\begin{enumerate}
    \item Being able to train a big enough neural network
    \item Huge amount of labelled data
\end{enumerate}

The process of training a neural network is iterative:
\begin{figure}[htb]
    \centering
    \includegraphics[width=25em]{figures/train-nn-process}
\end{figure}

It could take a good amount of time to train a neural network, which affects your productivity.
Faster computation helps to iterate and improve new algorithm.

\section{Neural Network Basics}
\subsection{Logistic Regression as a Neural Network}
\subsubsection{Binary Classification}
In a binary classification problem, the result is a discrete value output. For example:
\begin{itemize}
    \item account hacked (1) or compromised (0)
    \item a tumor malign (1) or benign (0)
\end{itemize}

\paragraph{Example: Cat vs Non-Cat}
The goal is to train a classifier that the input is an image represented by a feature vector,
$x$, and predicts whether the corresponding label $y$ is 1 or 0. In this case,
whether this is a cat image (1) or a non-cat image (0).

\begin{figure}[htb]
    \centering
    \includegraphics[width=35em]{figures/cat}
\end{figure}
An image is store in the computer in three separate matrices corresponding to the Red, Green, and
Blue color channels of the image. The three matrices have the same size as the image, for example,
the resolution of the cat image is 64 pixels $\times$ 64 pixels, the three matrices (RGB) are 64
$\times$ 64 each.

The value in a cell represents the pixel intensity which will be used to create a feature vector of
n-dimension. In pattern recognition and machine learning, a feature vector represents an object, in
this case, a cat or no cat.

To create a feature vector, $\Vector{x}$, the pixel intensity values will be ``unroll'' or
``reshape'' for each color. The dimension of the input feature vector $\Vector{x}$, is
$n_x = 64 \times 64 \times 3 = 12288$.
\begin{figure}[htb]
    \centering
    \includegraphics[width=10em]{figures/unrolled-image}
\end{figure}

\subsubsection{Notation}
single example: $(\Vector{x}, y)$, $\Vector{x} \in \Set{R}^{n_x}$, $y \in \{0, 1\}$

$m$ training examples: $\{(\Vector{x}^{(1)}, y^{(2)}), (\Vector{x}^{(2)}, y^{(2)}), \ldots,
(\Vector{x}^{(m)}, y^{(m)})\}$

$m = m_{train}$ \qquad $m_{test}$ = the number of test examples

\begin{IEEEeqnarray*}{rCl}
    \Matrix{X} = \left[
        \begin{array}{cccc}
            \vRule & \vRule & & \vRule \\
            \Vector{x^{(1)}} & \Vector{x^{(2)}} & \cdots & \Vector{x^{(m)}} \\
            \vRule & \vRule & & \vRule
        \end{array}
    \right]
    \qquad
    \Matrix{X} \in \Set{R}^{{n_x} \times m}
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \Vector{Y} = \left[
        \begin{array}{cccc}
            y^{(1)} & y^{(2)} & \cdots & y^{(m)}
        \end{array}
    \right]
    \qquad
    \Vector{Y} \in \Set{R}^{1 \times m}
\end{IEEEeqnarray*}

In Python/NumPy, \mintinline{numpy}{X.shape = (n_x, m), Y.shape = (1, m)}.

\subsubsection{Logistic Regression}
Logistic regression is a learning algorithm used in a supervised learning problem when the output
$y$ are all either zero or one. The goal of logistic regression is to minimize the error between
its predictions and training data.

\paragraph{Example: Cat vs Non-Cat}
Given an image represented by a feature vector $\Vector{x}$, the algorithm will evaluate the
probabilty of a cat being in that image.

Given $\Vector{x}$, want $\hat{y} = P(y=1|\Vector{x})$, $\Vector{x} \in \Set{R}^{n_x}$, $0 \leq
\hat{y} \leq 1$

Parameters: $\Vector{w} \in \Set{R}^{n_x}$, $b \in \Set{R}$

Output: \sout{$\hat{y} = \Vector{w}^T \Vector{x} + b$} \quad
$\hat{y} = \sigma (\Vector{w}^T\Vector{x} + b)$, where $\sigma(z) = \frac{1}{1+e^{-z}}$.
\begin{figure}[htb]
    \centering
    \includegraphics[width=25em]{figures/sigmoid}
    \caption{Sigmoid}
    \label{fig:sigmoid}
\end{figure}

$(\Vector{w}^T\Vector{x} + b)$ is a linear function $(a\Vector{x} + b)$, but since we are looking
for a probability constraint between [0, 1], the sigmoid function is used. The function is bounded
between [0, 1] as shown in the graph~\ref{fig:sigmoid}.

Some observations from the sigmoid function graph:
\begin{itemize}
    \item If $z$ is a large positive number, then $\sigma(z) = 1$
    \item If $z$ is small or large negative number, then $\sigma(z) = 0$
    \item If $z = 0$, then $\sigma(z) = 0.5$
\end{itemize}

\paragraph{Logistic Regression cost function}
$\hat{y}^{(i)} = \sigma (\Vector{w}^T \Vector{x}^{(i)} + b)$, where
$\sigma(z^{(i)}) = \frac{1}{1+e^{-z^{(i)}}}$

Given $\{(\Vector{x}^{(1)}, y^{(2)}), (\Vector{x}^{(2)}, y^{(2)}), \ldots,
(\Vector{x}^{(m)}, y^{(m)})\}$, want $\hat{y}^{(i)} \approx y^{(i)}$.

\paragraph{Loss (error) function:} (for single example)
\begin{IEEEeqnarray*}{rCl}
    \Cal{L}(\hat{y}, y) = -(y\log{\hat{y}} + (1-y)\log(1-\hat{y}))
\end{IEEEeqnarray*}

If $y = 1$: $\Cal{L}(\hat{y}, y) = -\log \hat{y}$ $\leftarrow$ want $\log \hat{y}$ large, want
$\hat{y}$ large.

If $y = 0$: $\Cal{L}(\hat{y}, y) = -\log(1-\hat{y})$ $\leftarrow$ want $\log(1-\hat{y})$ large,
want $\hat{y}$ small.

The loss function measures the discrepancy between the prediction ($\hat{y^{(i)}}$) and the desired
output ($y^{(i)}$). In other words, the loss function computes the error for a single training
example.

Note: Why can't use $\Cal{L}(\hat{y}, y) = \frac{1}{2}(\hat{y}-y)^2$? Because
$\Cal{L}(\hat{y}, y) = -(y\log{\hat{y}} + (1-y)\log(1-\hat{y}))$ is convex, however,
$\Cal{L}(\hat{y}, y) = \frac{1}{2}(\hat{y}-y)^2$ is non-convex.

\paragraph{Cost function:} (for entire training set)
\begin{IEEEeqnarray*}{rCl}
    J(\Vector{w}, b) = \frac{1}{m} \sum_{i=1}^m \Cal{L}(\hat{y}^{(i)}, y^{(i)}) = - \frac{1}{m}
    \sum_{i=1}^m[(y^{(i)}\log(\hat{y}^{(i)})) + (1-y^{(i)})\log(1-\hat{y}^{(i)})]
\end{IEEEeqnarray*}

The cost function is the average of the loss function of the entire training set. We are going to
find the parameters $\Vector{w}$ and $b$ that minimize the overall cost function.

\paragraph{Gradient Descent}
\begin{figure}[htb]
    \centering
    \includegraphics[width=25em]{figures/gradient-descent}
    \caption{Gradient descent. (Ignore $b$ here)}
\end{figure}

\begin{algorithm}[htb]
\Repeat{iteration = MaxIteration}{
        $\displaystyle{\Vector{w} := \Vector{w}
        - \alpha \frac{\partial J(\Vector{w}, b)}{\partial \Vector{w}}}$ \\
        $\displaystyle{b := b - \alpha \frac{\partial J(\Vector{w}, b)}{\partial b}}$
}
\end{algorithm}

Note: We often use ``d$\Vector{w}$'' to denote
$\displaystyle{\frac{\partial J(\Vector{w}, b)}{\partial \Vector{w}}}$, use
``d$b$'' to denote $\displaystyle{\frac{\partial J(\Vector{w}, b)}{\partial b}}$. In other words,
we use ``d$var$'' to denote $\displaystyle\frac{\text{d}FinalOutputVar}{\text{d}var}$ or
$\displaystyle\frac{\partial FinalOutputVar}{\partial var}$.

\paragraph{Gradient on single example:}
\begin{IEEEeqnarray*}{rCl}
    z = \Vector{w}^T \Vector{x} + b
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \hat{y} = a = \sigma(z) = \frac{1}{1 + e^{-z}}
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \Cal{L}(a, y) = -(y\log(a) + (1-y)\log(1-a))
\end{IEEEeqnarray*}

\begin{figure}[htb]
    \centering
    \includegraphics[width=35em]{figures/lr-gradient-descent}
    \caption{The computation graph of logistic regression gradient descent}
    \label{fig:lr-gradient-descent}
\end{figure}

According to the computation graph~\ref{fig:lr-gradient-descent}, go backwards to compute the
derivatives:
\begin{IEEEeqnarray*}{rCl}
    \text{d}a = \frac{\text{d}\Cal{L}(a, y)}{\text{d}a} = -\frac{y}{a} + \frac{1-y}{1-a}
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \text{d}z = \frac{\text{d}\Cal{L}(a, y)}{\text{d}z} = \frac{\text{d}\Cal{L}}{\text{d}a} \cdot
    \frac{\text{d}a}{\text{d}z} = (-\frac{y}{a} + \frac{1-y}{1-a}) \cdot a(1-a) = a - y
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \text{d}w_1 = \frac{\partial \Cal{L}}{\partial w_1} = x_1 \text{d}z = x_1 (a-y)
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \text{d}w_2 = \frac{\partial \Cal{L}}{\partial w_2} = x_2 \text{d}z = x_2 (a-y)
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \text{d}b = \frac{\partial \Cal{L}}{\partial b} = \text{d}z = a - y
\end{IEEEeqnarray*}

\paragraph{Gradient on m examples:}
\begin{IEEEeqnarray*}{rCl}
    J(\Vector{w}, b) = \frac{1}{m} \sum_{i=1}^m \Cal{L}(a^{(i)}, y^{(i)})
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    a^{(i)} = \hat{y^{(i)}} = \sigma(z^{(i)}) = \sigma(\Vector{w}^T \Vector{x}^{(i)} + b)
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \frac{\partial J(\Vector{w}, b)}{\partial w_1} = \frac{1}{m} \sum_{i=1}^m
    \frac{\partial \Cal{L}(a^{(i)}, y^{(i)})}{\partial w_1} = \frac{1}{m} \sum_{i=1}^m
    \text{d}w_1^{(i)}
\end{IEEEeqnarray*}

The Algorithm~\ref{alg:lr_gradient_descent} is the algorithm of logistic regression gradient
descent on m examples. It uses two for-loops, so it's less efficient than use vertorization.

\begin{algorithm}[htb]
    \tcc{Initialization}
    $J = 0;$ \\
    \For{$j = 1$ \KwTo $n$}{
        $\text{d}w_j = 0$ \\
    }
    $\text{d}b = 0;$

    \tcc{Compute cost and derivatives}
    \For{$i = 0$ \KwTo $m$}{
        $z^{(i)} = \Vector{w}^T \Vector{x^{(i)}} + b;$ \\
        $a^{(i)} = \sigma(z^{(i)});$ \\
        $J = J - [y^{(i)} \log a^{(i)} + (1-y^{(i)})\log (1-a^{(i)})];$ \\
        $\text{d}z^{(i)} = a^{(i)} - y^{(i)};$ \\
        \For{$j = 1$ \KwTo $n$}{
            $\text{d}w_j = \text{d}w_j + x_j^{(i)} \text{d}z^{(i)};$ \\
        }
        $\text{d}b = \text{d}b + \text{d}z^{(i)}$
    }

    \tcc{Get the average}
    $J = J / m;$ \\
    \For{$j = 1$ \KwTo $n$}{
        $\text{d}w_j = \text{d}w_j / m$
    }
    $\text{d}b = \text{d}b / m;$

    \tcc{Gradient descent}
    \For{$j = 1$ \KwTo $n$}{
        $\text{d}w_j = \text{d}w_j - \alpha \text{d}w_j$
    }
    $b = b - \alpha \text{d}b$
    \caption{Logistic regression gradient descent on m examples}
    \label{alg:lr_gradient_descent}
\end{algorithm}

\subsection{Python and Vectorization}
\subsubsection{Vectorization}
\paragraph{What is vectorization?}
\begin{IEEEeqnarray*}{rCl}
    z = \Vector{w}^T \Vector{x} + b \qquad\qquad
    \Vector{w} = \left[\begin{array}{c}
        \vdots \\
        \vdots \\
    \end{array} \right], \qquad
    \Vector{x} = \left[\begin{array}{c}
        \vdots \\
        \vdots \\
    \end{array} \right], \qquad
    \Vector{w} \in \Set{R}^{n_x}, \quad
    \Vector{x} \in \Set{R}^{n_x}
\end{IEEEeqnarray*}

\begin{multicols}{2}
Non vectorized:
\begin{minted}{numpy}
    z = 0
    for i in range(n_x):
        z += w[i] * x[i]
    z += b
\end{minted}
\columnbreak
Vectorized:
\begin{minted}{numpy}
    z = np.dot(w, x) + b
\end{minted}
\end{multicols}

\begin{IEEEeqnarray*}{rCl}
    \left\{
        \begin{array}{r}
            \text{CPU} \\
            \text{GPU}
        \end{array}
    \right.
    \qquad \text{SIMD - Single Instruction Multiple Data}
\end{IEEEeqnarray*}

\subsubsection{More Vectorization Examples}
\paragraph{Neural network programming guideline}
Whenever possible, avoid explicit for-loops.

For example, compute $\Vector{u} = \Vector{A} \Vector{v}$. $\Vector{A} \in \Set{R}^{m \times n}$,
$\Vector{v} \in \Set{R}^{n}$.

\begin{multicols}{2}
Non-vectorized: $\displaystyle u_i = \sum_j \Vector{A}_{ij} v_j$
\begin{minted}{numpy}
    u = np.zeros((n, 1))
    for i in range(A.shape[0]):
        for j in range(A.shape[1]):
            u[i] += A[i][j] * v[j]
\end{minted}
\columnbreak
Vectorized:
\begin{minted}{numpy}
    u = np.dot(A, v)
\end{minted}
\end{multicols}

\paragraph{Vectors and matrix valued functions}
Say you need to apply the exponential operation on every element of a matrix/vector.
\begin{IEEEeqnarray*}{rCl}
    \Vector{v} = \left[
        \begin{array}{c}
            v_1 \\
            \vdots \\
            v_n
        \end{array}
    \right]
    \longrightarrow
    \Vector{u} = \left[
        \begin{array}{c}
            e^{v_1} \\
            \vdots \\
            e^{v_n}
        \end{array}
    \right]
\end{IEEEeqnarray*}

\begin{multicols}{2}
Non-vectorized:
\begin{minted}{numpy}
    u = np.zeors((n, 1))
    for i in range(n):
        u[i] = math.exp(v[i])
\end{minted}
\columnbreak
Vectorized:
\begin{minted}{numpy}
    u = np.exp(v)
\end{minted}
\end{multicols}

\paragraph{Logistic regression derivatives}
\begin{algorithm}[htb]
    J = 0 \\
    \tcc{$\text{d}w_1 = 0, \text{d}w_2 = 0, \ldots, \text{d}w_{n_x}$}
    $\text{d}\Vector{w}$ = np.zeros(($n_x$, 1)) \\
    $\text{d}b$ = 0 \\
    \For{$i = 1$ \KwTo $m$}{
        $z^{(i)} = \Vector{w}^T x^{(i)} + b$ \\
        $a^{(i)} = \sigma(z^{(i)})$ \\
        $J = J - [y^{(i)}\log \hat{y}^{(i)} + (1-y^{(i)})\log (1-\hat{y}^{(i)})]$ \\
        $\text{d}z^{(i)} = a^{(i)} - y^{(i)}$ \\
        \tcc{
            $\text{d}w_1 = \text{d}w_1 + x_1^{(i)} \text{d}z^{(i)}$ \\
            $\text{d}w_2 = \text{d}w_2 + x_2^{(i)} \text{d}z^{(i)}$ \\
            \ldots \\
            $\text{d}w_{n_x} = \text{d}w_{n_x} + x_{n_x}^{(i)} \text{d}z^{(i)}$
        }
        $\text{d}\Vector{w} = \text{d}\Vector{w} + x^{(i)}\text{d}z^{(i)}$ \\
        $\text{d}b = \text{d}b + \text{d}z^{(i)}$ \\
    }
    $J = J / m$ \\
    \tcc{
        $\text{d}w_1 = \text{d}w_1 / m$ \\
        $\text{d}w_2 = \text{d}w_2 / m$ \\
        \ldots \\
        $\text{d}w_{n_x} = \text{d}w_{n_x} / m$
    }
    $\text{d}\Vector{w} = \text{d}\Vector{w} / m$ \\
    $\text{d}b = \text{d}b / m$
    \caption{Replace the inner for-loop by vectorization in logistic regression}
\end{algorithm}

\subsubsection{Vectorizing Logistic Regression}
Inference process:
\begin{IEEEeqnarray*}{rCl}
    z^{(1)} = \Vector{w}^T \Vector{x^{(1)}} + b \qquad z^{(2)} = \Vector{w}^T \Vector{x^{(2)}} + b
    \qquad \cdots \qquad z^{(m)} = \Vector{w}^T \Vector{x^{(m)}} + b
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    a^{(1)} = \sigma (z^{(1)}) \qquad a^{(2)} = \sigma (z^{(2)}) \qquad \cdots \qquad
    a^{(m)} = \sigma (z^{(m)})
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \Matrix{X} = \left[
        \begin{array}{cccc}
            \vRule & \vRule & & \vRule \\
            \Vector{x^{(1)}} & \Vector{x^{(2)}} & \cdots & \Vector{x^{(m)}} \\
            \vRule & \vRule & & \vRule
        \end{array}
    \right]
    \qquad
    \Matrix{X} \in \Set{R}^{{n_x} \times m}
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \Vector{Z} = \left[
        \begin{array}{cccc}
            z^{(1)} & z^{(2)} & \cdots & z^{(m)}
        \end{array}
    \right]
    = \Vector{w}^T \Matrix{X}
    + \underbrace{\left[\begin{array}{cccc}
        b & b & \cdots & b
    \end{array}\right]}_{1 \times m}
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \Vector{A} = \left[
        \begin{array}{cccc}
            a^{(1)} & a^{(2)} & \cdots & a^{(m)}
        \end{array}
    \right]
    = \sigma(\Vector{Z})
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \text{d}z^{(1)} = a^{(1)} - y^{(1)} \qquad \text{d}z^{(2)} = a^{(2)} - y^{(2)} \qquad \cdots
    \qquad \text{d}z^{(m)} = a^{(m)} - y^{(m)}
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \text{d}\Vector{Z} = \left[
        \begin{array}{cccc}
            \text{d}z^{(1)} & \text{d}z^{(2)} & \cdots & \text{d}z^{(m)}
        \end{array}
    \right]
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \Vector{Y} = \left[
        \begin{array}{cccc}
            y^{(1)} & y^{(2)} & \cdots & y^{(m)}
        \end{array}
    \right]
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \text{d}\Vector{Z} = \Vector{A} - \Vector{Y} = \left[
        \begin{array}{cccc}
            a^{(1)}-y^{(1)} & a^{(2)}-y^{(2)} & \cdots & a^{(m)}-y^{(m)}
        \end{array}
    \right]
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \text{d}b = \frac{1}{m} \sum_{i=1}^m \text{d}z^{(i)}
    \longrightarrow
    \text{d}b = \frac{1}{m} \text{np.sum(}\text{d}\Vector{Z}\text{)}
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \text{d}\Vector{w} = \frac{1}{m} \left[
        \begin{array}{cccc}
            \vRule & \vRule & & \vRule \\
            \Vector{x^{(1)}} & \Vector{x^{(2)}} & \cdots & \Vector{x^{(m)}} \\
            \vRule & \vRule & & \vRule
        \end{array}
    \right]
    \left[
        \begin{array}{c}
            \text{d}z^{(1)} \\
            \text{d}z^{(2)} \\
            \vdots \\
            \text{d}z^{(m)}
        \end{array}
    \right]
    = \frac{1}{m} \underbrace{\left[
        \Vector{x}^{(1)}\text{d}z^{(1)} + \Vector{x}^{(2)}\text{d}z^{(2)} + \cdots
        + \Vector{x}^{(m)}\text{d}z^{(m)}
    \right]}_{n \times 1}
    \longrightarrow
    \text{d}\Vector{w} = \frac{1}{m} \Matrix{X} \text{d}\Vector{Z}^T
\end{IEEEeqnarray*}

Vectorized (in a single iteration):
\begin{IEEEeqnarray*}{rCl}
    \Vector{Z} = \Vector{w}^T\Matrix{X} + b \longrightarrow \text{np.dot(w.T, X) + b}
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \Vector{A} = \sigma(\Vector{Z})
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \text{d}\Vector{Z} = \Vector{A} - \Vector{Y}
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \text{d}\Vector{w} = \frac{1}{m} \Matrix{X}(\text{d}\Vector{Z}^T)
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \text{d}b = \frac{1}{m} \text{np.sum(d}\Vector{Z}\text{)}
\end{IEEEeqnarray*}

Then update $\Vector{w}$ and $b$ for each iteration:
\begin{IEEEeqnarray*}{rCl}
    \Vector{w} = \Vector{w} - \alpha \text{d}\Vector{w}
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    b = b - \alpha \text{d}b
\end{IEEEeqnarray*}

\subsubsection{Broadcasting in Python}
According to Figure~\ref{fig:foods-calories}, denote the matrix in the figure as $\Matrix{A}$,
calculate the percentages of calories from Carbs, Proteins, Fats for each of four foods. Try do that
without explicit for-loop.

\begin{figure}[htb]
    \centering
    \includegraphics[width=25em]{figures/foods-calories}
    \caption{Calories from Carbs, Proteins, Fats in 100g of different foods}
    \label{fig:foods-calories}
\end{figure}

\begin{minted}{numpy}
    cal = A.sum(axis=0) # sum vertically, pass axis=1 to sum horizontally
    # broadcasting, A.shape = (3, 4), cal.shape = (1, 4)
    percentage = 100 * A / (cal.reshape(1, 4))
\end{minted}

\paragraph{Broadcasting examples}
\begin{IEEEeqnarray*}{rCl}
    \left[\begin{array}{c} 1 \\ 2 \\ 3 \\ 4 \end{array}\right] + 100
    = \left[\begin{array}{c} 1 \\ 2 \\ 3 \\ 4 \end{array}\right]
    + \left[\begin{array}{c} 100 \\ 100 \\ 100 \\ 100 \end{array} \right]
    = \left[\begin{array}{c} 101 \\ 102 \\ 103 \\ 104 \end{array} \right]
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \left[\begin{array}{ccc} 1 & 2 & 3 \\ 4 & 5 & 6 \end{array}\right]
    + \left[\begin{array}{ccc} 100 & 200 & 300 \end{array}\right]
    = \left[\begin{array}{ccc} 1 & 2 & 3 \\ 4 & 5 & 6 \end{array}\right]
    + \left[\begin{array}{ccc} 100 & 200 & 300 \\ 100 & 200 & 300 \end{array}\right]
    = \left[\begin{array}{ccc} 101 & 202 & 303 \\ 104 & 205 & 306 \end{array}\right]
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \left[\begin{array}{ccc} 1 & 2 & 3 \\ 4 & 5 & 6 \end{array}\right]
    + \left[\begin{array}{c} 100 \\ 200 \end{array}\right]
    = \left[\begin{array}{ccc} 1 & 2 & 3 \\ 4 & 5 & 6 \end{array}\right]
    + \left[\begin{array}{ccc} 100 & 100 & 100 \\ 200 & 200 & 200 \end{array}\right]
\end{IEEEeqnarray*}

(Note: In MATLAB/Octave, the \mintinline{matlab}{bsxfun} seems to have the same feature, it can
apply element-wise operation to two arrays with implicit expansion enabled.)

\paragraph{General principle of broadcasting}
\begin{IEEEeqnarray*}{rCl}
    \underbrace{\Matrix{Matrix}}_{(m, n)} \qquad
    \begin{array}{c} + \\ - \\ * \\ / \end{array} \qquad
    \underbrace{\Vector{Vector}}_{(1, n) or (m, 1)} \qquad
    \longrightarrow  \qquad \underbrace{\Matrix{Matrix}}_{(m, n)}
\end{IEEEeqnarray*}

\subsubsection{A Note on Python/NumPy Vectors}
For broadcasting:
\begin{IEEEeqnarray*}{rCl}
    \left\{\begin{array}{rl}
        \text{Strenght:} & \text{expressivity, flexibility} \\
        \text{Weakness:} & \text{may introduce subtle bugs}
    \end{array}\right.
\end{IEEEeqnarray*}

\begin{minted}{numpy}
    >>> import numpy as np
    >>> a = np.random.randn(5)
    >>> a   # rank 1 array, do not use in this course
    array([-0.40700705, -1.27728182,  0.10255894,  0.06871343, -1.01614418])
    >>> a.shape
    (5,)
    >>> a = a.reshape((5, 1))       # column vector
    >>> a
    array([[-0.40700705],
           [-1.27728182],
           [ 0.10255894],
           [ 0.06871343],
           [-1.01614418]])
    >>> a = np.random.randn(5, 1)   # column vector
    >>> a
    array([[ 1.32238445],
           [-2.09932992],
           [ 0.29040232],
           [-1.31295795],
           [-1.05893313]])
    >>> a.shape
    (5, 1)
    >>> a = np.random.randn(1, 5)   # row vector
    >>> a
    array([[-0.7020727 , -0.54867968,  1.38088584,  0.69785511, -0.2510519 ]])
    >>> a.shape
    (1, 5)
    >>> assert(a.shape == (1, 5))
    >>> assert(a.shape == (5, 1))
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    AssertionError
\end{minted}

\subsubsection{Explanation of Logistic Regression Cost Function (Optional)}
Logistic regression cost function:
\begin{IEEEeqnarray*}{rCl}
    \hat{y} = \sigma(\Vector{w}^T \Vector{x} + b), \qquad
    \text{where } \sigma(z) = \frac{1}{1+e^{-z}}.
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \left.\begin{array}{rl}
        \text{If }y=1\text{: } & P(y|x) = \hat{y} \\
        \text{If }y=0\text{: } & P(y|x) = 1 - \hat{y}
    \end{array}\right\}
    P(y|x) = \hat{y}^y (1-\hat{y})^{(1-y)}
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \log P(y|x) = y \log\hat{y} + (1-y)\log(1-\hat{y}) = -\Cal{L}(\hat{y}, y)
\end{IEEEeqnarray*}

Cost on m examples: (Maximum Likelihood Estimation)
\begin{IEEEeqnarray*}{rCl}
    \log P(\text{labels in training set}) = \log \prod_{i=1}^m P(y^{(i)}|x^{(i)})
    = \underbrace{\sum_{i=1}^m \log P(y^{(i)}|x^{(i)})}_{-\Cal{L}(\hat{y}^{(i)}, y^{(i)})}
    = -\sum_{(i=1)}^m \Cal{L}(\hat{y}^{(i)}, y^{(i)})
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \underset{\text{minimize}}{J(\Vector{w}, b)}
    = \frac{1}{m} \sum_{i=1}^m \Cal{L}(\hat{y}^{(i)}, y^{(i)})
\end{IEEEeqnarray*}

\section{Shallow Neural Network}
\subsection{What is a Neural Netork?}
\begin{figure}[htb]
    \centering
    \includegraphics[width=15em]{figures/shallow-nn}
    \includegraphics[width=50em]{figures/shallow-nn-compute}
    \caption{The example of a shallow neural network}
    \label{fig:shallow-nn}
\end{figure}

Figure~\ref{fig:shallow-nn} shows an example of a shallow neural network.

Notation: Use superscript $[i]$ to denote the i-th layer; use the superscript $(i)$ to denote the
i-th example in dataset.

\subsection{Neural Network Representation}
As is shown in Figure~\ref{fig:nn-representation}, $\Vector{a^{[i]}}$ denotes the activation of the
i-th layer.
\begin{figure}[htb]
    \centering
    \includegraphics[width=40em]{figures/nn-representation}
    \caption{The representation of a neural network}
    \label{fig:nn-representation}
\end{figure}

\subsection{Computing a Neural Network's Output}
As the Figure~\ref{fig:neuron-compuation} shows, the compuation of a single neuron includes two
parts: the first part, $\Vector{z} = \Vector{w}^T\Vector{x} + b$; the second part,
$\Vector{a} = \sigma(\Vector{z})$.
\begin{figure}[htb]
    \centering
    \includegraphics[width=20em]{figures/neuron-computation}
    \caption{The computation of a single neuron}
    \label{fig:neuron-compuation}
\end{figure}

\begin{figure}[htb]
    \centering
    \includegraphics[width=40em]{figures/nn-first-layer-computation}
    \caption{The computation of the first layer of a neural network}
    \label{fig:nn-first-layer-computation}
\end{figure}

The Figure~\ref{fig:nn-first-layer-computation} shows the compuation of the neural network's first
layer. Cause it uses a for-loop, it is less efficient. According to it, we can generize a
vectorized version:
\begin{IEEEeqnarray*}{rCl}
    \Vector{z^{[1]}} = \left[\begin{array}{c}
        z_1^{[1]} \\ z_2^{[1]} \\ z_3^{[1]} \\ z_4^{[1]}
    \end{array}\right] \qquad
    \Matrix{W^{[1]}} = \left[\begin{array}{c}
        \hRule \Vector{w_1^{[1]}}^T \hRule \\
        \hRule \Vector{w_2^{[1]}}^T \hRule \\
        \hRule \Vector{w_3^{[1]}}^T \hRule \\
        \hRule \Vector{w_4^{[1]}}^T \hRule
    \end{array}\right] \qquad
    \Vector{x} = \Vector{a^{[0]}} = \left[\begin{array}{c}
        x_1 \\ x_2 \\ x_3
    \end{array}\right] \qquad
    \Vector{b} = \left[\begin{array}{c}
        b_1^{[1]} \\ b_2^{[1]} \\ b_3^{[1]} \\ b_4^{[1]}
    \end{array}\right]
\end{IEEEeqnarray*}

Given input $\Vector{x} (\Vector{a^{[0]}})$:
\begin{IEEEeqnarray*}{rCl}
    \Vector{z^{[1]}} = \Matrix{W^{[1]}} \Vector{a^{[0]}} + \Vector{b^{[1]}} \qquad
    \Vector{a^{[1]}} = \sigma(\Vector{z^{[1]}}) \qquad
    \Vector{z^{[2]}} = \Matrix{W^{[2]}} \Vector{a^{[1]}} + \Vector{b^{[2]}} \qquad
    \Vector{a^{[2]}} = \sigma(\Vector{z^{[2]}})
\end{IEEEeqnarray*}

\section{Vectorizing across Multiple Examples}
For single example:
\begin{IEEEeqnarray*}{rCl}
    \Vector{x} \longrightarrow \Vector{a^{[2]}} = \Vector{\hat{y}}
\end{IEEEeqnarray*}

For m examples:
\begin{IEEEeqnarray*}{rCl}
    \Vector{x^{(1)}} \longrightarrow \Vector{a^{[2](1)}} = \Vector{\hat{y}^{(1)}} \qquad
    \Vector{x^{(2)}} \longrightarrow \Vector{a^{[2](2)}} = \Vector{\hat{y}^{(2)}} \qquad
    \ldots \qquad
    \Vector{x^{(m)}} \longrightarrow \Vector{a^{[2](m)}} = \Vector{\hat{y}^{(m)}} \qquad
\end{IEEEeqnarray*}

Non-vectorized:
\begin{algorithm}[htb]
    \For{$i = 1$ \KwTo $m$}{
        $\Vector{z^{[1](i)}} = \Matrix{W^{[1]}}\Vector{x^{(i)}} + \Vector{b^{[1]}}$ \\
        $\Vector{a^{[1](i)}} = \sigma(\Vector{z^{[1](1)}})$ \\
        $\Vector{z^{[2](1)}} = \Matrix{W^{[2]}}\Vector{a^{[1](i)}} + \Vector{b^{[2]}}$ \\
        $\Vector{a^{[2](i)}} = \sigma(\Vector{z^{[2](i)}})$
    }
\end{algorithm}

\begin{IEEEeqnarray*}{rCl}
    \text{Let} \quad \Matrix{X} = \underbrace{\left[\begin{array}{cccc}
        \vRule & \vRule & & \vRule \\
        \Vector{x^{(1)}} & \Vector{x^{(2)}} & \cdots & \Vector{x^{(m)}} \\
        \vRule & \vRule & & \vRule
    \end{array}\right]}_{(n_x, m)}
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \text{then} \quad \Matrix{Z^{[1]}} = \underbrace{\left[\begin{array}{cccc}
        \vRule & \vRule & & \vRule \\
        \Vector{z^{[1](1)}} & \Vector{z^{[1](2)}} & \cdots & \Vector{z^{[1](m)}} \\
        \vRule & \vRule & & \vRule
    \end{array}\right]}_{(\text{hidden units}, \text{training examples})} \qquad
    \Matrix{A^{[1]}} = \underbrace{\left[\begin{array}{cccc}
        \vRule & \vRule & & \vRule \\
        \Vector{a^{[1](1)}} & \Vector{a^{[1](2)}} & \cdots & \Vector{a^{[1](m)}} \\
        \vRule & \vRule & & \vRule
    \end{array}\right]}_{(\text{hidden units}, \text{training examples})}
\end{IEEEeqnarray*}

Vectorized:
\begin{IEEEeqnarray*}{rCl}
    \Matrix{Z^{[1]}} = \Matrix{W^{[1]}} \Matrix{A^{[0]}} + \Vector{b^{[1]}}
    = \Matrix{W^{[1]}} \Matrix{X} + \Vector{b^{[1]}}
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \Matrix{A^{[1]}} = \sigma(\Matrix{Z^{[1]}})
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \Matrix{Z^{[2]}} = \Matrix{W^{[2]}} \Matrix{A^{[1]}} + \Vector{b^{[2]}}
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \Matrix{A^{[2]}} = \sigma(\Matrix{Z^{[2]}})
\end{IEEEeqnarray*}

\subsection{Explanation for Vectorized Implementation}
\begin{IEEEeqnarray*}{rCl}
    \Vector{z^{[1](1)}} = \Matrix{W^{[1]}}\Vector{x^{(1)}} + \Vector{b^{[1]}}, \quad
    \Vector{z^{[1](2)}} = \Matrix{W^{[1]}}\Vector{x^{(2)}} + \Vector{b^{[1]}}, \quad
    \ldots, \quad
    \Vector{z^{[1](m)}} = \Matrix{W^{[1]}}\Vector{x^{(m)}} + \Vector{b^{[1]}}
\end{IEEEeqnarray*}

\begin{IEEEeqnarray*}{rCl}
    \Matrix{W^{[1]}} = \left[\begin{array}{c}
        \hRule \Vector{w_1^{[1]}}^T \hRule \\
        \hRule \Vector{w_2^{[1]}}^T \hRule \\
        \hRule \Vector{w_3^{[1]}}^T \hRule \\
        \hRule \Vector{w_4^{[1]}}^T \hRule
    \end{array}\right]
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \Matrix{W^{[1]}}{\color{purple} \Vector{x^{(1)}}} = {\color{purple} \left[\begin{array}{c}
        \cdot \\ \cdot \\ \cdot \\ \cdot
    \end{array}\right]} \qquad
    \Matrix{W^{[1]}}{\color{green} \Vector{x^{(2)}}} = {\color{green} \left[\begin{array}{c}
        \cdot \\ \cdot \\ \cdot \\ \cdot
    \end{array}\right]} \qquad
    \cdots \qquad
    \Matrix{W^{[1]}}{\color{yellow} \Vector{x^{(m)}}} = {\color{yellow} \left[\begin{array}{c}
        \cdot \\ \cdot \\ \cdot \\ \cdot
    \end{array}\right]}
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \Matrix{W^{[1]}}
    \left[
    {\color{purple}\begin{array}{c} \vRule \\ \Vector{x^{(1)}} \\ \vRule \end{array}}
    {\color{green}\begin{array}{c} \vRule \\ \Vector{x^{(2)}} \\ \vRule \end{array}}
    \cdots
    {\color{yellow}\begin{array}{c} \vRule \\ \Vector{x^{(m)}} \\ \vRule \end{array}}
    \right] + \Vector{b^{[1]}}
    = \left[{\color{purple} \begin{array}{c} \cdot \\ \cdot \\ \cdot \\ \cdot \end{array}}
    {\color{green} \begin{array}{c} \cdot \\ \cdot \\ \cdot \\ \cdot \end{array}} \cdots
    {\color{yellow} \begin{array}{c} \cdot \\ \cdot \\ \cdot \\ \cdot \end{array}}\right]
    + \Vector{b^{[1]}}
    = \left[
    {\color{purple}\begin{array}{c} \vRule \\ \Vector{z^{[1](1)}} \\ \vRule \end{array}}
    {\color{green}\begin{array}{c} \vRule \\ \Vector{z^{[1](2)}} \\ \vRule \end{array}}
    \cdots
    {\color{yellow}\begin{array}{c} \vRule \\ \Vector{z^{[1](m)}} \\ \vRule \end{array}}
    \right] = \Matrix{Z^{[1]}}
\end{IEEEeqnarray*}

So, $\Matrix{W^{[1]}\Vector{x^{(i)}}} + \Vector{b^{[1]}} = \Vector{z^{[1](i)}}$,
$\Matrix{Z^{[1]}} = \Matrix{W^{[1]}}\Matrix{X} + \Vector{b^{[1]}}$.

\subsection{Activation Functions}
Given $\Vector{x}$:
\begin{IEEEeqnarray*}{rCl}
    \Vector{z^{[1]}} = \Matrix{W^{[1]}}\Vector{x} + \Vector{b^{[1]}}
\end{IEEEeqnarray*}
{\centering \sout{$\Vector{a^{[1]}} = \sigma(\Vector{z^{[1]}})$} \par}
\begin{IEEEeqnarray*}{rCl}
    \Vector{a^{[1]}} = g^{[1]}(\Vector{z^{[1]}})
\end{IEEEeqnarray*}
\begin{IEEEeqnarray*}{rCl}
    \Vector{z^{[2]}} = \Matrix{W^{[2]}}\Vector{a^{[1]}} + b^{[2]}
\end{IEEEeqnarray*}
{\centering \sout{$\Vector{a^{[2]}} = \sigma(\Vector{z^{[2]}})$} \par}
\begin{IEEEeqnarray*}{rCl}
    \Vector{a^{[2]}} = g^{[2]}(\Vector{z^{[2]}})
\end{IEEEeqnarray*}

We use $g(z)$ to denote activation function. Sometimes we can use other activation function instead
of $\sigma(z)$ function. Different layers of the neural network may have different activation
function, so we can use $g^{[i]}(z)$ to denote the i-th layer's activation function of a neural
network.







\end{document}
